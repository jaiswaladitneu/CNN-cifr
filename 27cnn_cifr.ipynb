{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "27cnn_cifr.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtRkD_KXwCST"
      },
      "source": [
        "# import keras\n",
        "# from keras.datasets import cifar10\n",
        "# from keras.models import Model, Sequential\n",
        "# from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "# from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "# from keras.layers import Concatenate\n",
        "# from keras.optimizers import Adam\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1RJggTlwCPV"
      },
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-4HhVtFwCNp"
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "l = 40\n",
        "num_filter = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2v-NoFXwB3E",
        "outputId": "d96516c6-1fb7-4122-ca86-a5a9faa20b11"
      },
      "source": [
        "# Load CIFAR10 Data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUPAcmQAwLB5",
        "outputId": "684b4ac2-50ee-4444-916a-2d36aaf8d107"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FluaOKwAwKu4",
        "outputId": "6e0ccc64-3d1d-4b2c-9869-499035cc6a65"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8d39autwe-f"
      },
      "source": [
        "# Dense Block\n",
        "def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l): \n",
        "        BatchNorm = layers.BatchNormalization()(temp)\n",
        "        relu = layers.Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp\n",
        "\n",
        "## transition Blosck\n",
        "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    return avg\n",
        "\n",
        "#output layer\n",
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = layers.Flatten()(AvgPooling)\n",
        "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
        "    return output"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh_LcVJhweyv"
      },
      "source": [
        "num_filter = 12\n",
        "dropout_rate = 0.2\n",
        "l = 12\n",
        "input = layers.Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "Sh72Dcciwm_J",
        "outputId": "a3f07716-140c-4dbf-9e77-715f4c843d53"
      },
      "source": [
        "#https://arxiv.org/pdf/1608.06993.pdf\n",
        "from IPython.display import IFrame, YouTubeVideo\n",
        "YouTubeVideo(id='-W6y8xnd--U', width=600)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"600\"\n",
              "            height=\"300\"\n",
              "            src=\"https://www.youtube.com/embed/-W6y8xnd--U\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7f504c8200d0>"
            ],
            "image/jpeg": "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\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8Eo6YTywmyD",
        "outputId": "08116ee0-2e2d-4372-fdf9-f82fc01320ac"
      },
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 12)   324         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 12)   48          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 12)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 6)    648         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32, 32, 6)    0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 18)   0           conv2d[0][0]                     \n",
            "                                                                 dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 18)   72          concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 18)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 6)    972         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 6)    0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 24)   0           concatenate[0][0]                \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 24)   96          concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 24)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 6)    1296        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 6)    0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 30)   0           concatenate_1[0][0]              \n",
            "                                                                 dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 30)   120         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 30)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 6)    1620        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 6)    0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 36)   0           concatenate_2[0][0]              \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 36)   144         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 36)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 6)    1944        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32, 32, 6)    0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 42)   0           concatenate_3[0][0]              \n",
            "                                                                 dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 42)   168         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 42)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 6)    2268        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 32, 32, 6)    0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 48)   0           concatenate_4[0][0]              \n",
            "                                                                 dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 48)   192         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 6)    2592        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32, 32, 6)    0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 54)   0           concatenate_5[0][0]              \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 54)   216         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 54)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 6)    2916        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 32, 32, 6)    0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 60)   0           concatenate_6[0][0]              \n",
            "                                                                 dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 60)   240         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 60)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 6)    3240        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 32, 32, 6)    0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 66)   0           concatenate_7[0][0]              \n",
            "                                                                 dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 66)   264         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 66)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 6)    3564        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 32, 32, 6)    0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 72)   0           concatenate_8[0][0]              \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 72)   288         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 72)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 6)    3888        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 32, 32, 6)    0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 78)   0           concatenate_9[0][0]              \n",
            "                                                                 dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 78)   312         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 78)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 6)    4212        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 32, 32, 6)    0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 84)   0           concatenate_10[0][0]             \n",
            "                                                                 dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 84)   336         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 84)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 6)    504         activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32, 32, 6)    0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 6)    0           dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 6)    24          average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 6)    0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 6)    324         activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 16, 16, 6)    0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 16, 16, 12)   0           average_pooling2d[0][0]          \n",
            "                                                                 dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 12)   48          concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 12)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 6)    648         activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 16, 16, 6)    0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 16, 16, 18)   0           concatenate_12[0][0]             \n",
            "                                                                 dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 18)   72          concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 18)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 6)    972         activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 16, 16, 6)    0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 16, 16, 24)   0           concatenate_13[0][0]             \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 24)   96          concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 24)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 6)    1296        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 16, 16, 6)    0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 16, 16, 30)   0           concatenate_14[0][0]             \n",
            "                                                                 dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 30)   120         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 30)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 6)    1620        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 16, 16, 6)    0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 16, 16, 36)   0           concatenate_15[0][0]             \n",
            "                                                                 dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 36)   144         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 36)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 6)    1944        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 16, 16, 6)    0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 42)   0           concatenate_16[0][0]             \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 42)   168         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 42)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 6)    2268        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 16, 16, 6)    0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 48)   0           concatenate_17[0][0]             \n",
            "                                                                 dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   192         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 6)    2592        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 16, 16, 6)    0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 54)   0           concatenate_18[0][0]             \n",
            "                                                                 dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 54)   216         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 54)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 6)    2916        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 16, 16, 6)    0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 60)   0           concatenate_19[0][0]             \n",
            "                                                                 dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 60)   240         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 60)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 6)    3240        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 16, 16, 6)    0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 16, 16, 66)   0           concatenate_20[0][0]             \n",
            "                                                                 dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 66)   264         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 66)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 6)    3564        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 16, 16, 6)    0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 72)   0           concatenate_21[0][0]             \n",
            "                                                                 dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 72)   288         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 72)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 6)    3888        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 16, 16, 6)    0           conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 16, 16, 78)   0           concatenate_22[0][0]             \n",
            "                                                                 dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 78)   312         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 78)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 6)    468         activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 16, 16, 6)    0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 8, 8, 6)      0           dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 6)      24          average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 6)      0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 6)      324         activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 8, 8, 6)      0           conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 8, 8, 12)     0           average_pooling2d_1[0][0]        \n",
            "                                                                 dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 12)     48          concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 12)     0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 6)      648         activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 8, 8, 6)      0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 8, 8, 18)     0           concatenate_24[0][0]             \n",
            "                                                                 dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 18)     72          concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 18)     0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 6)      972         activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 8, 8, 6)      0           conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 8, 8, 24)     0           concatenate_25[0][0]             \n",
            "                                                                 dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 24)     96          concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 24)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 6)      1296        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 8, 8, 6)      0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 8, 8, 30)     0           concatenate_26[0][0]             \n",
            "                                                                 dropout_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 30)     120         concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 30)     0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 6)      1620        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 8, 8, 6)      0           conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 8, 8, 36)     0           concatenate_27[0][0]             \n",
            "                                                                 dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 36)     144         concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 36)     0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 6)      1944        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_31 (Dropout)            (None, 8, 8, 6)      0           conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 8, 8, 42)     0           concatenate_28[0][0]             \n",
            "                                                                 dropout_31[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 42)     168         concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 42)     0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 6)      2268        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_32 (Dropout)            (None, 8, 8, 6)      0           conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 8, 8, 48)     0           concatenate_29[0][0]             \n",
            "                                                                 dropout_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 48)     192         concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 48)     0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 6)      2592        activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_33 (Dropout)            (None, 8, 8, 6)      0           conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 8, 8, 54)     0           concatenate_30[0][0]             \n",
            "                                                                 dropout_33[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 54)     216         concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 54)     0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 6)      2916        activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_34 (Dropout)            (None, 8, 8, 6)      0           conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 8, 8, 60)     0           concatenate_31[0][0]             \n",
            "                                                                 dropout_34[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 60)     240         concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 60)     0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 6)      3240        activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_35 (Dropout)            (None, 8, 8, 6)      0           conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 8, 8, 66)     0           concatenate_32[0][0]             \n",
            "                                                                 dropout_35[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 66)     264         concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 66)     0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 6)      3564        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_36 (Dropout)            (None, 8, 8, 6)      0           conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 8, 8, 72)     0           concatenate_33[0][0]             \n",
            "                                                                 dropout_36[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 72)     288         concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 72)     0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 6)      3888        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 8, 8, 6)      0           conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 8, 8, 78)     0           concatenate_34[0][0]             \n",
            "                                                                 dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 8, 8, 78)     312         concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 78)     0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 6)      468         activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_38 (Dropout)            (None, 8, 8, 6)      0           conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 4, 4, 6)      0           dropout_38[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 4, 4, 6)      24          average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 4, 4, 6)      0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 4, 4, 6)      324         activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 4, 4, 6)      0           conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 4, 4, 12)     0           average_pooling2d_2[0][0]        \n",
            "                                                                 dropout_39[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 4, 4, 12)     48          concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 4, 4, 12)     0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 4, 4, 6)      648         activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_40 (Dropout)            (None, 4, 4, 6)      0           conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 4, 4, 18)     0           concatenate_36[0][0]             \n",
            "                                                                 dropout_40[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 4, 4, 18)     72          concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 4, 4, 18)     0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 4, 4, 6)      972         activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 4, 4, 6)      0           conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 4, 4, 24)     0           concatenate_37[0][0]             \n",
            "                                                                 dropout_41[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 4, 4, 24)     96          concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 4, 4, 24)     0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 4, 4, 6)      1296        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 4, 4, 6)      0           conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 4, 4, 30)     0           concatenate_38[0][0]             \n",
            "                                                                 dropout_42[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 4, 4, 30)     120         concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 4, 4, 30)     0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 4, 4, 6)      1620        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_43 (Dropout)            (None, 4, 4, 6)      0           conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 4, 4, 36)     0           concatenate_39[0][0]             \n",
            "                                                                 dropout_43[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 4, 4, 36)     144         concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 4, 4, 36)     0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 4, 4, 6)      1944        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_44 (Dropout)            (None, 4, 4, 6)      0           conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 4, 4, 42)     0           concatenate_40[0][0]             \n",
            "                                                                 dropout_44[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 4, 4, 42)     168         concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 4, 4, 42)     0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 4, 4, 6)      2268        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_45 (Dropout)            (None, 4, 4, 6)      0           conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 4, 4, 48)     0           concatenate_41[0][0]             \n",
            "                                                                 dropout_45[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 4, 4, 48)     192         concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 4, 4, 48)     0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 4, 4, 6)      2592        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_46 (Dropout)            (None, 4, 4, 6)      0           conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 4, 4, 54)     0           concatenate_42[0][0]             \n",
            "                                                                 dropout_46[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 4, 4, 54)     216         concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 4, 4, 54)     0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 4, 4, 6)      2916        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_47 (Dropout)            (None, 4, 4, 6)      0           conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 4, 4, 60)     0           concatenate_43[0][0]             \n",
            "                                                                 dropout_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 4, 4, 60)     240         concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 4, 4, 60)     0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 4, 4, 6)      3240        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 4, 4, 6)      0           conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 4, 4, 66)     0           concatenate_44[0][0]             \n",
            "                                                                 dropout_48[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 4, 4, 66)     264         concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 4, 4, 66)     0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 4, 4, 6)      3564        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_49 (Dropout)            (None, 4, 4, 6)      0           conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 4, 4, 72)     0           concatenate_45[0][0]             \n",
            "                                                                 dropout_49[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 4, 4, 72)     288         concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 4, 4, 72)     0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 4, 4, 6)      3888        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_50 (Dropout)            (None, 4, 4, 6)      0           conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 4, 4, 78)     0           concatenate_46[0][0]             \n",
            "                                                                 dropout_50[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 4, 4, 78)     312         concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 4, 4, 78)     0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 2, 2, 78)     0           activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 312)          0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           3130        flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 118,918\n",
            "Trainable params: 114,394\n",
            "Non-trainable params: 4,524\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efWU7DjCwtOj",
        "outputId": "e9b3e650-759e-4d85-ba04-b7f874caca06"
      },
      "source": [
        "print(len(model.layers))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "262\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVQ6aUQnwtHG"
      },
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t7c7SFiwwIx"
      },
      "source": [
        "# model.fit(X_train, y_train,\n",
        "#                     batch_size=batch_size,\n",
        "#                     epochs=epochs,\n",
        "#                     verbose=1, \n",
        "#                     validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg9g6MwBvo2R"
      },
      "source": [
        "### CNN on CIFR Assignment:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPB2MpAavswd"
      },
      "source": [
        "1.  Please visit this link to access the state-of-art DenseNet code for reference - DenseNet - cifar10 notebook link\n",
        "2.  You need to create a copy of this and \"retrain\" this model to achieve 90+ test accuracy. \n",
        "3.  You cannot use DropOut layers.\n",
        "4.  You MUST use Image Augmentation Techniques.\n",
        "5.  You cannot use an already trained model as a beginning points, you have to initilize as your own\n",
        "6.  You cannot run the program for more than 300 Epochs, and it should be clear from your log, that you have only used 300 Epochs\n",
        "7.  You cannot use test images for training the model.\n",
        "8.  You cannot change the general architecture of DenseNet (which means you must use Dense Block, Transition and Output blocks as mentioned in the code)\n",
        "9.  You are free to change Convolution types (e.g. from 3x3 normal convolution to Depthwise Separable, etc)\n",
        "10. You cannot have more than 1 Million parameters in total\n",
        "11. You are free to move the code from Keras to Tensorflow, Pytorch, MXNET etc. \n",
        "12. You can use any optimization algorithm you need. \n",
        "13. You can checkpoint your model and retrain the model from that checkpoint so that no need of training the model from first if you lost at any epoch while training. You can directly load that model and Train from that epoch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-xYvR2vz3GG"
      },
      "source": [
        "# import keras\n",
        "# from keras.datasets import cifar10\n",
        "# from keras.models import Model, Sequential\n",
        "# from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "# from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "# from keras.layers import Concatenate\n",
        "# from keras.optimizers import Adam\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzDkM6p3z9c5"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7h9o-_9xSm7"
      },
      "source": [
        "# Hyperparameters\n",
        "compression = 1\n",
        "num_filter = 17\n",
        "dropout_rate = 0\n",
        "l = 13\n",
        "num_classes = 10\n",
        "\n",
        "# batch_size = 128\n",
        "# num_classes = 10\n",
        "# epochs = 10\n",
        "# l = 40\n",
        "# num_filter = 12\n",
        "# compression = 0.5\n",
        "# dropout_rate = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fBuVFmXz9xa",
        "outputId": "7a910564-5fc0-4901-9332-d1d2c683a5ea"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrWtAwyI0Bjt",
        "outputId": "ab042423-3f1d-4a26-b704-03d5537fde80"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNA4WnfR0FUY",
        "outputId": "d64e46c9-e004-4f81-995f-557758bba142"
      },
      "source": [
        "print(X_test.shape)\n",
        "print(y_test.shape)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQar38Rt0IVp"
      },
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes) #one hot encoding\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)  # one hot encoding\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeZNx8ML0QAk",
        "outputId": "32a1418e-a43e-426c-ba95-b49b06ce6056"
      },
      "source": [
        "mean_X_tr = np.mean(X_train, axis=(0,1,2))\n",
        "mean_X_tr"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([125.30691805, 122.95039414, 113.86538318])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fCgjeFP0SyE",
        "outputId": "a381a219-f9f1-4c4e-fc38-61dcd2db58ae"
      },
      "source": [
        "std_X_tr = np.std(X_train, axis=(0,1,2))\n",
        "std_X_tr"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([62.99321928, 62.08870764, 66.70489964])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HckhD01P0WR6"
      },
      "source": [
        "X_train = (X_train - mean_X_tr) / std_X_tr #normalization\n",
        "X_test = (X_test - mean_X_tr) / std_X_tr"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5_h7xgA0Y40"
      },
      "source": [
        "#data augmentation\n",
        "train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,rotation_range=40,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.2,zoom_range=0.2,horizontal_flip=True) #image generator\n",
        "test_datagen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255) \n",
        "train_generator=train_datagen.flow(X_train,y_train,batch_size=150)\n",
        "test_generator=test_datagen.flow(X_test,y_test,batch_size=150)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LtFmkCJ0h5K"
      },
      "source": [
        "#https://www.google.com/search?q=callback+function&rlz=1C1RLNS_enIN923IN923&oq=callback&aqs=chrome.1.69i57j0i433l2j0l2j69i60j69i61l2.5990j0j7&sourceid=chrome&ie=UTF-8\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('val_accuracy') > 0.90):\n",
        "      print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(0.90*100))\n",
        "      self.model.stop_training = True\n",
        "\n",
        "val_acc_callback=myCallback()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v08TTmGM0pki"
      },
      "source": [
        "filepath='/content/best_model_h5'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBU710ov0rmL"
      },
      "source": [
        "#https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
        "model_best=tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=0, save_best_only=True,save_weights_only=True, mode='auto', save_freq='epoch')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFLAVnfE0wWU"
      },
      "source": [
        "#f= no of filter\n",
        "#d=no of dense block\n",
        "#t=no of transition blk\n",
        "\n",
        "def no_of_connection(l):\n",
        "  a=(l * (l+ 1))/2 # each layer has connection to its preceding and subsequent layer directly\n",
        "  return a\n",
        "\n",
        "def total_parametres(l, f,d,t):\n",
        "  input= 3 * 3 * 3 * f\n",
        "  dense= d * ((f * 3 * 3 * f *no_of_connection(l)) + ( 4 * f * no_of_connection(l)))\n",
        "  para=t * ( (1 * 1 * f * f* ((l +1)) + 4 * f * (l+1)))\n",
        "  out=((2 * 2 * f * (l+1) * 10) + 10) + (4 * f * (l+1))\n",
        "  return input,dense,para,out"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3c0CJa_06Sb",
        "outputId": "60dc24f8-d9b5-48f0-ddb0-33d6594f8ea7"
      },
      "source": [
        "sum(total_parametres(13,17,4,3))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "997451.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ltn-5Lq_0_KL"
      },
      "source": [
        "# Dense Block\n",
        "def denseblock(input, num_filter = 17, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l): \n",
        "        BatchNorm = layers.BatchNormalization()(temp)\n",
        "        relu = layers.Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp\n",
        "\n",
        "## transition Blosck\n",
        "def transition(input, num_filter = 17, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    return avg\n",
        "\n",
        "#output layer\n",
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = layers.Flatten()(AvgPooling)\n",
        "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
        "    return output"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_3om4ha1N1q"
      },
      "source": [
        "input = layers.Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = denseblock(Third_Transition, num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqP-rBdl1DEe"
      },
      "source": [
        "model = Model(inputs=[input], outputs=[output])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAHMuJ9W1L9C",
        "outputId": "a1f334ce-10ef-4e19-e265-5fdeb67dda95"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 17)   459         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 17)   68          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 17)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 17)   2601        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 34)   0           conv2d[0][0]                     \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 34)   136         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 34)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 17)   5202        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 51)   0           concatenate[0][0]                \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 51)   204         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 51)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 17)   7803        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 68)   0           concatenate_1[0][0]              \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 68)   272         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 68)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 17)   10404       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 85)   0           concatenate_2[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 85)   340         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 85)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 17)   13005       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 102)  0           concatenate_3[0][0]              \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 102)  408         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 102)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 17)   15606       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 119)  0           concatenate_4[0][0]              \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 119)  476         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 119)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 17)   18207       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 136)  0           concatenate_5[0][0]              \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 136)  544         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 136)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 17)   20808       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 153)  0           concatenate_6[0][0]              \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 153)  612         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 153)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 17)   23409       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 170)  0           concatenate_7[0][0]              \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 170)  680         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 170)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 17)   26010       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 187)  0           concatenate_8[0][0]              \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 187)  748         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 187)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 17)   28611       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 204)  0           concatenate_9[0][0]              \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 204)  816         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 204)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 17)   31212       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 221)  0           concatenate_10[0][0]             \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 221)  884         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 221)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 17)   33813       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 32, 32, 238)  0           concatenate_11[0][0]             \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 238)  952         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 238)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 17)   4046        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 17)   0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 17)   68          average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 17)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 17)   2601        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 16, 16, 34)   0           average_pooling2d[0][0]          \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 34)   136         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 34)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 17)   5202        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 16, 16, 51)   0           concatenate_13[0][0]             \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 51)   204         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 51)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 17)   7803        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 16, 16, 68)   0           concatenate_14[0][0]             \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 68)   272         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 68)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 17)   10404       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 16, 16, 85)   0           concatenate_15[0][0]             \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 85)   340         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 85)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 17)   13005       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 102)  0           concatenate_16[0][0]             \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 102)  408         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 102)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 17)   15606       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 119)  0           concatenate_17[0][0]             \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 119)  476         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 119)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 17)   18207       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 136)  0           concatenate_18[0][0]             \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 136)  544         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 136)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 17)   20808       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 153)  0           concatenate_19[0][0]             \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 153)  612         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 153)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 17)   23409       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 16, 16, 170)  0           concatenate_20[0][0]             \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 170)  680         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 170)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 17)   26010       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 187)  0           concatenate_21[0][0]             \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 187)  748         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 187)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 17)   28611       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 16, 16, 204)  0           concatenate_22[0][0]             \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 204)  816         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 204)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 17)   31212       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 16, 16, 221)  0           concatenate_23[0][0]             \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 16, 16, 221)  884         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 221)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 17)   33813       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 16, 16, 238)  0           concatenate_24[0][0]             \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 238)  952         concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 238)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 17)   4046        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 8, 8, 17)     0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 17)     68          average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 17)     0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 17)     2601        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 8, 8, 34)     0           average_pooling2d_1[0][0]        \n",
            "                                                                 conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 34)     136         concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 34)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 17)     5202        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 8, 8, 51)     0           concatenate_26[0][0]             \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 51)     204         concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 51)     0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 17)     7803        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 8, 8, 68)     0           concatenate_27[0][0]             \n",
            "                                                                 conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 68)     272         concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 68)     0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 17)     10404       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 8, 8, 85)     0           concatenate_28[0][0]             \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 85)     340         concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 85)     0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 17)     13005       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 8, 8, 102)    0           concatenate_29[0][0]             \n",
            "                                                                 conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 102)    408         concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 102)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 17)     15606       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 8, 8, 119)    0           concatenate_30[0][0]             \n",
            "                                                                 conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 119)    476         concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 119)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 17)     18207       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 8, 8, 136)    0           concatenate_31[0][0]             \n",
            "                                                                 conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 136)    544         concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 136)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 17)     20808       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 8, 8, 153)    0           concatenate_32[0][0]             \n",
            "                                                                 conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 153)    612         concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 153)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 17)     23409       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 8, 8, 170)    0           concatenate_33[0][0]             \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 170)    680         concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 170)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 17)     26010       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 8, 8, 187)    0           concatenate_34[0][0]             \n",
            "                                                                 conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 8, 8, 187)    748         concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 187)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 17)     28611       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 8, 8, 204)    0           concatenate_35[0][0]             \n",
            "                                                                 conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 8, 8, 204)    816         concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 8, 8, 204)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 8, 8, 17)     31212       activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 8, 8, 221)    0           concatenate_36[0][0]             \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 8, 8, 221)    884         concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 8, 8, 221)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 8, 8, 17)     33813       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 8, 8, 238)    0           concatenate_37[0][0]             \n",
            "                                                                 conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 8, 8, 238)    952         concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 8, 8, 238)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 8, 8, 17)     4046        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 4, 4, 17)     0           conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 4, 4, 17)     68          average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 4, 4, 17)     0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 4, 4, 17)     2601        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 4, 4, 34)     0           average_pooling2d_2[0][0]        \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 4, 4, 34)     136         concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 4, 4, 34)     0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 4, 4, 17)     5202        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 4, 4, 51)     0           concatenate_39[0][0]             \n",
            "                                                                 conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 4, 4, 51)     204         concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 4, 4, 51)     0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 4, 4, 17)     7803        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 4, 4, 68)     0           concatenate_40[0][0]             \n",
            "                                                                 conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 4, 4, 68)     272         concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 4, 4, 68)     0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 4, 4, 17)     10404       activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 4, 4, 85)     0           concatenate_41[0][0]             \n",
            "                                                                 conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 4, 4, 85)     340         concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 4, 4, 85)     0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 4, 4, 17)     13005       activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 4, 4, 102)    0           concatenate_42[0][0]             \n",
            "                                                                 conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 4, 4, 102)    408         concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 4, 4, 102)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 4, 4, 17)     15606       activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 4, 4, 119)    0           concatenate_43[0][0]             \n",
            "                                                                 conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 4, 4, 119)    476         concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 4, 4, 119)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 4, 4, 17)     18207       activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 4, 4, 136)    0           concatenate_44[0][0]             \n",
            "                                                                 conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 4, 4, 136)    544         concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 4, 4, 136)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 4, 4, 17)     20808       activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 4, 4, 153)    0           concatenate_45[0][0]             \n",
            "                                                                 conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 4, 4, 153)    612         concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 4, 4, 153)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 4, 4, 17)     23409       activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 4, 4, 170)    0           concatenate_46[0][0]             \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 4, 4, 170)    680         concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 4, 4, 170)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 4, 4, 17)     26010       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_48 (Concatenate)    (None, 4, 4, 187)    0           concatenate_47[0][0]             \n",
            "                                                                 conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 4, 4, 187)    748         concatenate_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 4, 4, 187)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 4, 4, 17)     28611       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_49 (Concatenate)    (None, 4, 4, 204)    0           concatenate_48[0][0]             \n",
            "                                                                 conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 4, 4, 204)    816         concatenate_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 4, 4, 204)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 4, 4, 17)     31212       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_50 (Concatenate)    (None, 4, 4, 221)    0           concatenate_49[0][0]             \n",
            "                                                                 conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 4, 4, 221)    884         concatenate_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 4, 4, 221)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 4, 4, 17)     33813       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 4, 4, 238)    0           concatenate_50[0][0]             \n",
            "                                                                 conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 4, 4, 238)    952         concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 4, 4, 238)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 2, 2, 238)    0           activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 952)          0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           9530        flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 997,451\n",
            "Trainable params: 983,171\n",
            "Non-trainable params: 14,280\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwZdACH_1bBX",
        "outputId": "4e009ae6-08b2-4bad-a08f-b4731a8d7613"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf4aK_-I1hSA",
        "outputId": "217a83cc-7990-4217-a96e-07fd3b35682b"
      },
      "source": [
        "model.fit(train_generator,steps_per_epoch=len(X_train)/150,\n",
        "        epochs=300,verbose=1,\n",
        "        validation_data=test_generator,\n",
        "        validation_steps=len(X_test)/150,callbacks=[val_acc_callback,model_best])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "  6/333 [..............................] - ETA: 3:16 - loss: 2.4512 - accuracy: 0.1500WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2401s vs `on_train_batch_end` time: 0.2998s). Check your callbacks.\n",
            "333/333 [==============================] - 258s 655ms/step - loss: 1.7313 - accuracy: 0.3656 - val_loss: 3.6667 - val_accuracy: 0.1460\n",
            "Epoch 2/300\n",
            "333/333 [==============================] - 213s 638ms/step - loss: 1.3904 - accuracy: 0.4967 - val_loss: 1.4036 - val_accuracy: 0.5090\n",
            "Epoch 3/300\n",
            "333/333 [==============================] - 213s 639ms/step - loss: 1.2227 - accuracy: 0.5606 - val_loss: 1.6734 - val_accuracy: 0.4848\n",
            "Epoch 4/300\n",
            "333/333 [==============================] - 213s 639ms/step - loss: 1.1102 - accuracy: 0.6052 - val_loss: 1.2793 - val_accuracy: 0.5785\n",
            "Epoch 5/300\n",
            "333/333 [==============================] - 213s 638ms/step - loss: 1.0269 - accuracy: 0.6350 - val_loss: 1.1171 - val_accuracy: 0.6351\n",
            "Epoch 6/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.9524 - accuracy: 0.6634 - val_loss: 1.0752 - val_accuracy: 0.6388\n",
            "Epoch 7/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.8998 - accuracy: 0.6850 - val_loss: 1.1919 - val_accuracy: 0.6350\n",
            "Epoch 8/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.8489 - accuracy: 0.7022 - val_loss: 1.2367 - val_accuracy: 0.6309\n",
            "Epoch 9/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.8114 - accuracy: 0.7175 - val_loss: 1.1188 - val_accuracy: 0.6588\n",
            "Epoch 10/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.7785 - accuracy: 0.7302 - val_loss: 1.2969 - val_accuracy: 0.6364\n",
            "Epoch 11/300\n",
            "333/333 [==============================] - 215s 644ms/step - loss: 0.7455 - accuracy: 0.7419 - val_loss: 1.0769 - val_accuracy: 0.6722\n",
            "Epoch 12/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.7198 - accuracy: 0.7530 - val_loss: 0.9912 - val_accuracy: 0.7076\n",
            "Epoch 13/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.6958 - accuracy: 0.7572 - val_loss: 0.8645 - val_accuracy: 0.7248\n",
            "Epoch 14/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.6683 - accuracy: 0.7698 - val_loss: 1.1318 - val_accuracy: 0.6663\n",
            "Epoch 15/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.6497 - accuracy: 0.7757 - val_loss: 0.8005 - val_accuracy: 0.7537\n",
            "Epoch 16/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.6316 - accuracy: 0.7797 - val_loss: 0.5678 - val_accuracy: 0.8012\n",
            "Epoch 17/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.6153 - accuracy: 0.7869 - val_loss: 0.7315 - val_accuracy: 0.7717\n",
            "Epoch 18/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.5950 - accuracy: 0.7938 - val_loss: 0.6129 - val_accuracy: 0.7932\n",
            "Epoch 19/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.5780 - accuracy: 0.8009 - val_loss: 0.6090 - val_accuracy: 0.7938\n",
            "Epoch 20/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.5672 - accuracy: 0.8040 - val_loss: 0.6767 - val_accuracy: 0.7881\n",
            "Epoch 21/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.5526 - accuracy: 0.8065 - val_loss: 0.6222 - val_accuracy: 0.7985\n",
            "Epoch 22/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.5370 - accuracy: 0.8126 - val_loss: 0.8186 - val_accuracy: 0.7424\n",
            "Epoch 23/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.5273 - accuracy: 0.8167 - val_loss: 0.6413 - val_accuracy: 0.7991\n",
            "Epoch 24/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.5095 - accuracy: 0.8222 - val_loss: 0.7272 - val_accuracy: 0.7806\n",
            "Epoch 25/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.5112 - accuracy: 0.8223 - val_loss: 0.5860 - val_accuracy: 0.8121\n",
            "Epoch 26/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.4969 - accuracy: 0.8271 - val_loss: 1.0409 - val_accuracy: 0.7038\n",
            "Epoch 27/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.4870 - accuracy: 0.8311 - val_loss: 0.4931 - val_accuracy: 0.8376\n",
            "Epoch 28/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.4790 - accuracy: 0.8332 - val_loss: 0.5020 - val_accuracy: 0.8333\n",
            "Epoch 29/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.4672 - accuracy: 0.8380 - val_loss: 0.5794 - val_accuracy: 0.8070\n",
            "Epoch 30/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.4595 - accuracy: 0.8400 - val_loss: 0.7274 - val_accuracy: 0.7794\n",
            "Epoch 31/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.4564 - accuracy: 0.8416 - val_loss: 0.5031 - val_accuracy: 0.8331\n",
            "Epoch 32/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.4446 - accuracy: 0.8450 - val_loss: 0.4157 - val_accuracy: 0.8600\n",
            "Epoch 33/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.4339 - accuracy: 0.8485 - val_loss: 0.6526 - val_accuracy: 0.8039\n",
            "Epoch 34/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.4320 - accuracy: 0.8506 - val_loss: 0.5620 - val_accuracy: 0.8197\n",
            "Epoch 35/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.4211 - accuracy: 0.8530 - val_loss: 0.5452 - val_accuracy: 0.8198\n",
            "Epoch 36/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.4133 - accuracy: 0.8576 - val_loss: 0.4698 - val_accuracy: 0.8486\n",
            "Epoch 37/300\n",
            "333/333 [==============================] - 214s 640ms/step - loss: 0.4121 - accuracy: 0.8572 - val_loss: 0.6349 - val_accuracy: 0.8012\n",
            "Epoch 38/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.4036 - accuracy: 0.8592 - val_loss: 0.5434 - val_accuracy: 0.8273\n",
            "Epoch 39/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.4042 - accuracy: 0.8592 - val_loss: 0.6283 - val_accuracy: 0.8123\n",
            "Epoch 40/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.3968 - accuracy: 0.8612 - val_loss: 0.5724 - val_accuracy: 0.8164\n",
            "Epoch 41/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.3833 - accuracy: 0.8662 - val_loss: 0.5449 - val_accuracy: 0.8294\n",
            "Epoch 42/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.3756 - accuracy: 0.8674 - val_loss: 0.4837 - val_accuracy: 0.8423\n",
            "Epoch 43/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.3771 - accuracy: 0.8685 - val_loss: 0.5237 - val_accuracy: 0.8318\n",
            "Epoch 44/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.3648 - accuracy: 0.8736 - val_loss: 0.5237 - val_accuracy: 0.8318\n",
            "Epoch 45/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.3665 - accuracy: 0.8738 - val_loss: 0.5043 - val_accuracy: 0.8440\n",
            "Epoch 46/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.3628 - accuracy: 0.8737 - val_loss: 0.3790 - val_accuracy: 0.8699\n",
            "Epoch 47/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.3596 - accuracy: 0.8747 - val_loss: 0.5454 - val_accuracy: 0.8335\n",
            "Epoch 48/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.3488 - accuracy: 0.8784 - val_loss: 0.4337 - val_accuracy: 0.8577\n",
            "Epoch 49/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.3419 - accuracy: 0.8807 - val_loss: 0.5194 - val_accuracy: 0.8378\n",
            "Epoch 50/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.3469 - accuracy: 0.8790 - val_loss: 0.5260 - val_accuracy: 0.8376\n",
            "Epoch 51/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.3357 - accuracy: 0.8830 - val_loss: 0.4212 - val_accuracy: 0.8615\n",
            "Epoch 52/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.3367 - accuracy: 0.8814 - val_loss: 0.4122 - val_accuracy: 0.8685\n",
            "Epoch 53/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.3347 - accuracy: 0.8839 - val_loss: 0.4523 - val_accuracy: 0.8535\n",
            "Epoch 54/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.3282 - accuracy: 0.8849 - val_loss: 0.5523 - val_accuracy: 0.8355\n",
            "Epoch 55/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.3243 - accuracy: 0.8851 - val_loss: 0.6252 - val_accuracy: 0.8100\n",
            "Epoch 56/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.3217 - accuracy: 0.8878 - val_loss: 0.6213 - val_accuracy: 0.8185\n",
            "Epoch 57/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.3171 - accuracy: 0.8904 - val_loss: 0.4586 - val_accuracy: 0.8548\n",
            "Epoch 58/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.3197 - accuracy: 0.8889 - val_loss: 0.5771 - val_accuracy: 0.8303\n",
            "Epoch 59/300\n",
            "333/333 [==============================] - 214s 643ms/step - loss: 0.3121 - accuracy: 0.8899 - val_loss: 0.5415 - val_accuracy: 0.8398\n",
            "Epoch 60/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.3104 - accuracy: 0.8915 - val_loss: 0.4217 - val_accuracy: 0.8749\n",
            "Epoch 61/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.3040 - accuracy: 0.8935 - val_loss: 0.5649 - val_accuracy: 0.8440\n",
            "Epoch 62/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.3035 - accuracy: 0.8937 - val_loss: 0.4434 - val_accuracy: 0.8639\n",
            "Epoch 63/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.2986 - accuracy: 0.8943 - val_loss: 0.7966 - val_accuracy: 0.7912\n",
            "Epoch 64/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.2954 - accuracy: 0.8961 - val_loss: 0.4774 - val_accuracy: 0.8631\n",
            "Epoch 65/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.2934 - accuracy: 0.8969 - val_loss: 0.4362 - val_accuracy: 0.8668\n",
            "Epoch 66/300\n",
            "333/333 [==============================] - 213s 638ms/step - loss: 0.2920 - accuracy: 0.8983 - val_loss: 0.4915 - val_accuracy: 0.8533\n",
            "Epoch 67/300\n",
            "333/333 [==============================] - 213s 638ms/step - loss: 0.2866 - accuracy: 0.8982 - val_loss: 0.4818 - val_accuracy: 0.8554\n",
            "Epoch 68/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.2812 - accuracy: 0.9013 - val_loss: 0.4000 - val_accuracy: 0.8752\n",
            "Epoch 69/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.2799 - accuracy: 0.9022 - val_loss: 0.5821 - val_accuracy: 0.8341\n",
            "Epoch 70/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.2820 - accuracy: 0.9000 - val_loss: 0.4249 - val_accuracy: 0.8683\n",
            "Epoch 71/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.2747 - accuracy: 0.9041 - val_loss: 0.4803 - val_accuracy: 0.8553\n",
            "Epoch 72/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.2775 - accuracy: 0.9016 - val_loss: 0.3565 - val_accuracy: 0.8855\n",
            "Epoch 73/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.2710 - accuracy: 0.9067 - val_loss: 0.3875 - val_accuracy: 0.8780\n",
            "Epoch 74/300\n",
            "333/333 [==============================] - 214s 640ms/step - loss: 0.2706 - accuracy: 0.9034 - val_loss: 0.4517 - val_accuracy: 0.8679\n",
            "Epoch 75/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.2665 - accuracy: 0.9049 - val_loss: 0.5344 - val_accuracy: 0.8470\n",
            "Epoch 76/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.2676 - accuracy: 0.9070 - val_loss: 0.4086 - val_accuracy: 0.8722\n",
            "Epoch 77/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.2595 - accuracy: 0.9082 - val_loss: 0.5532 - val_accuracy: 0.8453\n",
            "Epoch 78/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.2634 - accuracy: 0.9071 - val_loss: 0.5763 - val_accuracy: 0.8445\n",
            "Epoch 79/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.2568 - accuracy: 0.9093 - val_loss: 0.3868 - val_accuracy: 0.8818\n",
            "Epoch 80/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.2566 - accuracy: 0.9101 - val_loss: 0.5036 - val_accuracy: 0.8498\n",
            "Epoch 81/300\n",
            "333/333 [==============================] - 214s 640ms/step - loss: 0.2542 - accuracy: 0.9113 - val_loss: 0.4052 - val_accuracy: 0.8806\n",
            "Epoch 82/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.2549 - accuracy: 0.9121 - val_loss: 0.4357 - val_accuracy: 0.8693\n",
            "Epoch 83/300\n",
            "333/333 [==============================] - 214s 640ms/step - loss: 0.2496 - accuracy: 0.9121 - val_loss: 0.4870 - val_accuracy: 0.8568\n",
            "Epoch 84/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.2490 - accuracy: 0.9128 - val_loss: 0.4894 - val_accuracy: 0.8583\n",
            "Epoch 85/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.2480 - accuracy: 0.9127 - val_loss: 0.3680 - val_accuracy: 0.8838\n",
            "Epoch 86/300\n",
            "333/333 [==============================] - 214s 643ms/step - loss: 0.2519 - accuracy: 0.9121 - val_loss: 0.3735 - val_accuracy: 0.8770\n",
            "Epoch 87/300\n",
            "333/333 [==============================] - 215s 643ms/step - loss: 0.2475 - accuracy: 0.9137 - val_loss: 0.4352 - val_accuracy: 0.8695\n",
            "Epoch 88/300\n",
            "333/333 [==============================] - 214s 643ms/step - loss: 0.2406 - accuracy: 0.9163 - val_loss: 0.4558 - val_accuracy: 0.8628\n",
            "Epoch 89/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.2380 - accuracy: 0.9157 - val_loss: 0.4361 - val_accuracy: 0.8730\n",
            "Epoch 90/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.2374 - accuracy: 0.9160 - val_loss: 0.5117 - val_accuracy: 0.8591\n",
            "Epoch 91/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.2354 - accuracy: 0.9171 - val_loss: 0.4100 - val_accuracy: 0.8756\n",
            "Epoch 92/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.2330 - accuracy: 0.9171 - val_loss: 0.3640 - val_accuracy: 0.8899\n",
            "Epoch 93/300\n",
            "333/333 [==============================] - 214s 643ms/step - loss: 0.2372 - accuracy: 0.9175 - val_loss: 0.4236 - val_accuracy: 0.8769\n",
            "Epoch 94/300\n",
            "333/333 [==============================] - 214s 643ms/step - loss: 0.2299 - accuracy: 0.9177 - val_loss: 0.4129 - val_accuracy: 0.8776\n",
            "Epoch 95/300\n",
            "333/333 [==============================] - 214s 643ms/step - loss: 0.2270 - accuracy: 0.9194 - val_loss: 0.3402 - val_accuracy: 0.8941\n",
            "Epoch 96/300\n",
            "333/333 [==============================] - 214s 643ms/step - loss: 0.2223 - accuracy: 0.9208 - val_loss: 0.5140 - val_accuracy: 0.8585\n",
            "Epoch 97/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.2310 - accuracy: 0.9180 - val_loss: 0.4450 - val_accuracy: 0.8741\n",
            "Epoch 98/300\n",
            "333/333 [==============================] - 215s 644ms/step - loss: 0.2225 - accuracy: 0.9224 - val_loss: 0.4659 - val_accuracy: 0.8684\n",
            "Epoch 99/300\n",
            "333/333 [==============================] - 214s 643ms/step - loss: 0.2260 - accuracy: 0.9197 - val_loss: 0.3822 - val_accuracy: 0.8842\n",
            "Epoch 100/300\n",
            "333/333 [==============================] - 214s 643ms/step - loss: 0.2212 - accuracy: 0.9215 - val_loss: 0.4771 - val_accuracy: 0.8695\n",
            "Epoch 101/300\n",
            "333/333 [==============================] - 215s 644ms/step - loss: 0.2165 - accuracy: 0.9250 - val_loss: 0.4258 - val_accuracy: 0.8770\n",
            "Epoch 102/300\n",
            "333/333 [==============================] - 215s 644ms/step - loss: 0.2161 - accuracy: 0.9245 - val_loss: 0.3621 - val_accuracy: 0.8892\n",
            "Epoch 103/300\n",
            "333/333 [==============================] - 215s 643ms/step - loss: 0.2178 - accuracy: 0.9247 - val_loss: 0.3896 - val_accuracy: 0.8864\n",
            "Epoch 104/300\n",
            "333/333 [==============================] - 214s 643ms/step - loss: 0.2176 - accuracy: 0.9236 - val_loss: 0.4760 - val_accuracy: 0.8671\n",
            "Epoch 105/300\n",
            "333/333 [==============================] - 215s 643ms/step - loss: 0.2160 - accuracy: 0.9238 - val_loss: 0.4755 - val_accuracy: 0.8655\n",
            "Epoch 106/300\n",
            "333/333 [==============================] - 215s 644ms/step - loss: 0.2128 - accuracy: 0.9267 - val_loss: 0.4772 - val_accuracy: 0.8627\n",
            "Epoch 107/300\n",
            "333/333 [==============================] - 214s 643ms/step - loss: 0.2142 - accuracy: 0.9253 - val_loss: 0.4432 - val_accuracy: 0.8709\n",
            "Epoch 108/300\n",
            "333/333 [==============================] - 215s 644ms/step - loss: 0.2113 - accuracy: 0.9258 - val_loss: 0.5050 - val_accuracy: 0.8620\n",
            "Epoch 109/300\n",
            "333/333 [==============================] - 215s 644ms/step - loss: 0.2119 - accuracy: 0.9252 - val_loss: 0.3654 - val_accuracy: 0.8897\n",
            "Epoch 110/300\n",
            "333/333 [==============================] - 215s 643ms/step - loss: 0.2044 - accuracy: 0.9277 - val_loss: 0.3467 - val_accuracy: 0.8954\n",
            "Epoch 111/300\n",
            "333/333 [==============================] - 214s 643ms/step - loss: 0.2106 - accuracy: 0.9250 - val_loss: 0.3967 - val_accuracy: 0.8840\n",
            "Epoch 112/300\n",
            "333/333 [==============================] - 215s 643ms/step - loss: 0.2107 - accuracy: 0.9260 - val_loss: 0.3710 - val_accuracy: 0.8865\n",
            "Epoch 113/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.2013 - accuracy: 0.9291 - val_loss: 0.4584 - val_accuracy: 0.8725\n",
            "Epoch 114/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.1999 - accuracy: 0.9291 - val_loss: 0.3674 - val_accuracy: 0.8882\n",
            "Epoch 115/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.2008 - accuracy: 0.9292 - val_loss: 0.4174 - val_accuracy: 0.8780\n",
            "Epoch 116/300\n",
            "333/333 [==============================] - 214s 640ms/step - loss: 0.2021 - accuracy: 0.9287 - val_loss: 0.4005 - val_accuracy: 0.8843\n",
            "Epoch 117/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.1974 - accuracy: 0.9309 - val_loss: 0.3492 - val_accuracy: 0.8959\n",
            "Epoch 118/300\n",
            "333/333 [==============================] - 214s 641ms/step - loss: 0.2011 - accuracy: 0.9296 - val_loss: 0.3998 - val_accuracy: 0.8857\n",
            "Epoch 119/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.1944 - accuracy: 0.9320 - val_loss: 0.3739 - val_accuracy: 0.8916\n",
            "Epoch 120/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.1941 - accuracy: 0.9310 - val_loss: 0.4194 - val_accuracy: 0.8799\n",
            "Epoch 121/300\n",
            "333/333 [==============================] - 214s 640ms/step - loss: 0.1943 - accuracy: 0.9304 - val_loss: 0.4715 - val_accuracy: 0.8722\n",
            "Epoch 122/300\n",
            "333/333 [==============================] - 213s 639ms/step - loss: 0.1906 - accuracy: 0.9321 - val_loss: 0.3354 - val_accuracy: 0.8994\n",
            "Epoch 123/300\n",
            "333/333 [==============================] - 214s 643ms/step - loss: 0.1937 - accuracy: 0.9319 - val_loss: 0.4660 - val_accuracy: 0.8709\n",
            "Epoch 124/300\n",
            "333/333 [==============================] - 215s 643ms/step - loss: 0.1895 - accuracy: 0.9327 - val_loss: 0.3968 - val_accuracy: 0.8884\n",
            "Epoch 125/300\n",
            "333/333 [==============================] - 214s 642ms/step - loss: 0.1891 - accuracy: 0.9329 - val_loss: 0.4497 - val_accuracy: 0.8799\n",
            "Epoch 126/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.1871 - accuracy: 0.9329 - val_loss: 0.4607 - val_accuracy: 0.8760\n",
            "Epoch 127/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.1832 - accuracy: 0.9358 - val_loss: 0.3836 - val_accuracy: 0.8861\n",
            "Epoch 128/300\n",
            "333/333 [==============================] - 213s 639ms/step - loss: 0.1865 - accuracy: 0.9345 - val_loss: 0.4211 - val_accuracy: 0.8833\n",
            "Epoch 129/300\n",
            "333/333 [==============================] - 214s 640ms/step - loss: 0.1828 - accuracy: 0.9349 - val_loss: 0.5003 - val_accuracy: 0.8645\n",
            "Epoch 130/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.1855 - accuracy: 0.9340 - val_loss: 0.4291 - val_accuracy: 0.8802\n",
            "Epoch 131/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.1832 - accuracy: 0.9362 - val_loss: 0.4851 - val_accuracy: 0.8721\n",
            "Epoch 132/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.1849 - accuracy: 0.9347 - val_loss: 0.4820 - val_accuracy: 0.8736\n",
            "Epoch 133/300\n",
            "333/333 [==============================] - 214s 640ms/step - loss: 0.1769 - accuracy: 0.9382 - val_loss: 0.4973 - val_accuracy: 0.8673\n",
            "Epoch 134/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.1793 - accuracy: 0.9364 - val_loss: 0.4890 - val_accuracy: 0.8712\n",
            "Epoch 135/300\n",
            "333/333 [==============================] - 213s 640ms/step - loss: 0.1803 - accuracy: 0.9354 - val_loss: 0.3394 - val_accuracy: 0.9018\n",
            "\n",
            "Reached 90.00% accuracy, so stopping training!!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdef697b090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBIde1LR1kvo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3934ad-b8b5-46c6-8e7c-5d28f707514e"
      },
      "source": [
        "# Test the model\n",
        "score = model.evaluate(test_generator, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "67/67 [==============================] - 12s 178ms/step - loss: 0.3394 - accuracy: 0.9018\n",
            "Test loss: 0.339419424533844\n",
            "Test accuracy: 0.9017999768257141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3t-nJQkzc26"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML3Iw0Rgzhry"
      },
      "source": [
        "* To make the accuracy 90 % let make the epoch exact 300 because as epoch increases accuracy will increase\n",
        "* And also fix parameter value less than 1000000"
      ]
    }
  ]
}